"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[514],{477:function(e,t,i){i.d(t,{Z:function(){return c}});var n=i(5893),r=i(7294),a=i(1417),s=i(1436),o=i(7814),h=i(1664),l=function(){var e=[{icon:s.Z__,link:"tel:+358449707667"},{icon:s.FU$,link:"mailto:robinkrokfors@gmail.com"},{icon:a.D9H,link:"https://www.linkedin.com/in/robin-krokfors-644768234/"},{icon:a.zhw,link:"https://github.com/robinkrokfors"}];return(0,n.jsx)("div",{className:" static xl:absolute top-0 left-0 flex flex-row flex-nowrap items-center w-full h-menu bg-main-50 xl:bg-transparent overflow-hidden z-50 ",children:(0,n.jsx)("div",{className:"flex-auto xl:ml-[50%] px-8 xl:px-16",children:(0,n.jsxs)("nav",{className:"flex flex-row flex-nowrap gap-8 items-center",children:[(0,n.jsx)("div",{children:(0,n.jsx)("ul",{className:"list-none flex flex-row items-center justify-center",children:e.map((function(e){return(0,n.jsx)(n.Fragment,{children:(0,n.jsx)("li",{className:"text-main-50",children:(0,n.jsx)("a",{href:e.link,target:"_blank",className:"inline-block p-3 px-4 social-link border-main-800 border-2",rel:"noreferrer",children:(0,n.jsx)(o.G,{className:"relative z-10",size:"lg",icon:e.icon})})})})}))})}),(0,n.jsx)("div",{className:"flex-auto h-[1px] bg-main-900"}),(0,n.jsx)("ul",{className:"flex flex-row flex-nowrap gap-4 list-none text-main-900",children:[{title:"Home",link:"/"},{title:"Projects",link:"/#projects"},{title:"Other",link:"/#other-projects"}].map((function(e,t){return(0,n.jsx)("li",{className:"transition-colors menu-link",children:(0,n.jsx)(h.default,{href:e.link,children:(0,n.jsx)("a",{className:"inline-block px-2",children:(0,n.jsx)("span",{className:"relative",children:e.title})})})},t)}))}),(0,n.jsx)("div",{className:"w-8 h-[1px] bg-main-900"})]})})})},c=function(e){var t=e.compact,i=e.children;return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(l,{}),(0,n.jsx)("div",{className:"w-100 flex flex-row items-stretch min-h-[600px] ".concat(t?"xl:max-h-screen":"xl:min-h-screen"),children:(0,n.jsx)("div",{className:"w-full flex flex-col xl:flex-row justify-center items-center",children:r.Children.map(i,(function(e,t){return(0,n.jsx)(n.Fragment,{children:0==t?(0,n.jsx)("div",{className:"basis-0 w-full xl:w-auto flex-grow flex-shrink h-full bg-main-900",children:e}):(0,n.jsx)("div",{className:"basis-0 w-full xl:w-auto xl:pt-menu flex-grow flex-shrink h-full bg-main-50",children:e})})}))})})]})}},8218:function(e,t,i){var n=i(5893),r=i(7294);function a(e,t){(null==t||t>e.length)&&(t=e.length);for(var i=0,n=new Array(t);i<t;i++)n[i]=e[i];return n}function s(e){return function(e){if(Array.isArray(e))return a(e)}(e)||function(e){if("undefined"!==typeof Symbol&&null!=e[Symbol.iterator]||null!=e["@@iterator"])return Array.from(e)}(e)||function(e,t){if(!e)return;if("string"===typeof e)return a(e,t);var i=Object.prototype.toString.call(e).slice(8,-1);"Object"===i&&e.constructor&&(i=e.constructor.name);if("Map"===i||"Set"===i)return Array.from(i);if("Arguments"===i||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(i))return a(e,t)}(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}t.Z=function(e){var t=e.media,i=e.className,a=r.useMemo((function(){var e=[i||""];return"image"===t.type?(0,n.jsx)("img",{className:["object-cover"].concat(s(e)).join(" "),src:t.source}):"video"===t.type?(0,n.jsx)("video",{className:e.join(" "),controls:!0,children:(0,n.jsx)("source",{src:t.source,type:"video/mp4"})}):"yt"===t.type?(0,n.jsx)("iframe",{className:e.join(" "),width:"100%",height:"100%",src:t.source,frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0}):(0,n.jsx)(n.Fragment,{})}),[t]);return(0,n.jsx)(n.Fragment,{children:a})}},1140:function(e,t,i){var n=i(5893);t.Z=function(e){var t=e.id,i=e.title,r=e.className,a=e.children;return(0,n.jsxs)("section",{id:t,className:"mb-8 ".concat(r||""),children:[i&&i.length>0?(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)("h3",{className:"text-main-900",children:i}),(0,n.jsx)("div",{className:"my-2 mb-4 w-8 h-1 bg-main-900"})]}):void 0,a]})}},9496:function(e,t,i){i.d(t,{XN:function(){return I},jt:function(){return v},l2:function(){return k}});var n=i(5893),r=i(1140),a=function(e){var t=e.children;return(0,n.jsx)("p",{children:t})},s=i(7294),o=function(e){var t=e.children;return(0,n.jsx)("div",{className:"flex flex-col gap-4 lg:flex-row",children:s.Children.map(t,(function(e){return(0,n.jsx)("div",{className:"flex-grow flex-shrink basis-0",children:e})}))})},h="/_next/static/media/img-ui-tool.4d0c627b.png",l="/_next/static/media/img-outline.e9f67e2b.png",c={id:"spite-blood-relic",title:"Spite - Blood Relic",summaryComponent:function(){return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a,{children:"This was the first game made at TGA where we made our own game engine, the game itself took a lot of inspiration from Diablo III."}),(0,n.jsx)(a,{children:"During engine development I was mostly focused on the rendering subsystem as well as the UI system, more details about these areas in their respective sections. Aside from this I also implemented support for animating skinned meshes, helped with scene management, added support for text rendering with multi-channel signed distance field fonts and helped with various other parts of the engine as well."}),(0,n.jsx)(a,{children:"I implemented various tools to speed up the development workflow both for me and others."})]})},longContentComponent:function(){return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.Z,{id:"ecs",title:"ECS",children:(0,n.jsx)(a,{children:"For this project we decided to go with an entity component system. There are a couple of reasons for this but mostly we wanted to try something we had not done before in our projects at TGA. It took some getting used to the thought process, after using it for a while we found it very pleasant to work with since it naturally separates data from the logic."})}),(0,n.jsx)(r.Z,{id:"ui-system",title:"UI System",children:(0,n.jsxs)(o,{children:[(0,n.jsx)("div",{children:(0,n.jsx)(a,{children:"For our UI system I took inspiration from settings and features available in other engines our team had worked with before. Features implemented include nested entities, ordering, anchors, pivots, fill modes for sprites (solid & radial), text rendering using multi-channel signed distance fields and more."})}),(0,n.jsx)("img",{width:"100%",height:"auto",src:h})]})}),(0,n.jsx)(r.Z,{id:"outlines",title:"Outlines",children:(0,n.jsxs)(o,{children:[(0,n.jsxs)("div",{children:[(0,n.jsx)(a,{children:"For rendering outlines I wanted to try something new and I had come up with some requirements for this system, first of all it needed to produce a nice looking outline on any mesh thrown at it, it should support both thin and thick outlines with little performance impact, support for soft/faded outlines as well as hard outlines. After researching for a while I found a promising method taking advantage of the jump flood algorithm."}),(0,n.jsx)(a,{children:"This method works as follows. First we render all meshes with an outline to a grayscale texture, at the same time we also mark passing pixels in the stencil buffer, with this texture we do our initial JFA setup by writing out the screen space UV coordinates for all filled texels in the previous pass."}),(0,n.jsxs)(a,{children:["Next we do the actual jump flooding by running a shader sampling 9 texels in a grid around the current fragment with a particular distance, we do this several times. The amount of times the shader needs to be run depends on the outline width, with the relation ",(0,n.jsx)("i",{children:"runs = log2(width)"}),"."]}),(0,n.jsx)(a,{children:"As a final step we run another shader, only once this time. The shader computes the distance for the current screen space UV coordinates to those sampled at the same location in the texture, if the distance is less or equal to the outline width we can write out the color of the outline, otherwise transparent. With this we now have a texture we can compose on top of our scene, using the stencil buffer from the first greyscale pass we can ensure we do not render to pixels inside the actual meshes."})]}),(0,n.jsx)("img",{width:"100%",height:"auto",src:l})]})})]})},sections:[{id:"summary",title:"Summary"},{id:"ecs",title:"ECS"},{id:"ui-system",title:"UI System"},{id:"outlines",title:"Outlines"}],platforms:["windows"],engine:{engineName:"Wondrous Machine"},media:[{type:"image",source:"/images/projects/the-eternal/img-0.png"},{type:"image",source:"/images/projects/the-eternal/img-1.png"},{type:"image",source:"/images/projects/the-eternal/img-2.png"},{type:"image",source:"/images/projects/the-eternal/img-3.png"},{type:"image",source:"/images/projects/the-eternal/img-4.png"},{type:"image",source:"/images/projects/the-eternal/img-5.png"}],videoShowcase:{type:"yt",source:"https://www.youtube-nocookie.com/embed/72UH-tYsbow"}},d={id:"tga-specialization",title:"Specialization",summaryComponent:function(){return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a,{children:"At the end of our second year at The Game Assembly we had a course where we were allowed to create almost anything we wanted. I was interested in exploring other rendering techniques than the deferred rendering pipeline we had created for our own engines. During development of our engine I spent a lot of time on the rendering system, during this time I stumbled upon several things that made the rendering code more complex and less streamlined than what I would have liked."}),(0,n.jsx)(a,{children:"Because of this, I took this project as an opportunity to try out some more modern techniques that not only offer better performance in common demanding situations, but also streamline the rendering pipeline. And so, the goal of this project was clear, I would implement some techniques that would streamline the rendering pipeline and bring down the complexity, remove unnecessary state changes, bring down the required amounts of shader combinations and implement clustered shading."})]})},longContentComponent:function(){return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(r.Z,{id:"clustered-shading",title:"Clustered Shading",children:[(0,n.jsx)(a,{children:"We had previously implemented deferred shading for opaque geometry to get better performance with our requirement for having tons of lights in the scene. In my research of finding a more modern solution that would offer even better performance I found clustered shading. Since this technique can be heavily parallelized, I wanted to implement the technique through compute shaders. Below is an explanation of how clustered shading works and what steps the engine performs to render a scene with it. "}),(0,n.jsx)(a,{children:"Clustered shading is an extension of tiled shading, one could think of clustered shading as being the 3D version of tiled shading. In tiled shading we split the screen into tiles of a set width and height, this builds a grid over the entire screen, for clustered shading we take this a step further by building a 3D grid of froxels, taking into account the perspective of the camera when building the grid. With the information about the boundaries of these cells in hand we now go through them all and look at the lights in the scene, our goal is to figure out if the volume of the lights intersects with the boundaries of the cell, and if so, we add it to the list of lights in the cell. We should now have information about which lights affect any given cell, we can now render the scene geometry, clustered shading can be combined with either deferred or forward rendering for different pros and cons. When it comes time to shade a fragment we need to figure out which cell it corresponds to, for this we need camera space position of the fragment, since the froxels were built relative to the camera. After we figure out the cell the pixel is inside we can get the list of lights affecting this pixel, and with this information we can now loop through them all and compute the final shaded color. "}),(0,n.jsxs)(a,{children:["For my implementation of clustered shading I decided to do all steps through compute shaders. The first step is to compute the froxels in camera space, this is also done through a compute shader, I decided to divide the screen into 16x9x24 chunks, since this matches the aspect ratio our games were designed for, although running it with a different aspect ratio is no problem either. To maximize usage in thread groups when dispatching I balanced the amount of threads to use and the amount of groups to dispatch, taking into consideration that the amount of threads in a group is usually 32 or 64 on modern GPUs, this was done to maximize the amounts of threads used in the groups.",(0,n.jsx)("br",{}),(0,n.jsx)("span",{children:"TODO: Add images, more text"})]}),(0,n.jsxs)(a,{children:["Now we need to add all lights intersecting any cell into the list of lights for that cell. This is again done through a compute shader, the input for this step will be the list of lights in the scene and the cluster configuration, for output",(0,n.jsx)("br",{}),(0,n.jsx)("span",{children:"TODO: Add images, more text"})]}),(0,n.jsx)(a,{children:"Finally, after all these steps we now have all the information needed to render the scene, as stated before we can use either deferred or forward rendering, I went with forward rendering this time, among other things it allows me to apply hardware MSAA. When the time comes to compute the shading of a fragment we compute or retrieve the camera space position, from this we can compute which cluster it corresponds to in the same way as before, from this we can extract the list of lights, looping through all lights and computing their contribution to the current fragment we get the final color. "})]}),(0,n.jsxs)(r.Z,{id:"compute-skinning",title:"Skinning with Compute shaders",children:[(0,n.jsx)(a,{children:"An annoying problem I faced while developing the rendering system for our engine, which also added extra complexity, is the fact that all animated meshes require extra care when rendering, all vertices need to be transformed by the corresponding weighted bone transforms."}),(0,n.jsx)(a,{children:"This is not a big problem per se, but it becomes burdensome when all these meshes require a separate vertex shader that applies these bone transforms, something that static meshes do not require. This requires binding an extra buffer for the bone transforms themselves, as well as binding another vertex shader. If we want to allow meshes to have a custom vertex shader, which might be useful for some vertex effects or such, we must also write yet another vertex shader with the same effect that also applies the bone transforms. We store our shaders in configurations, a configuration consisting of a vertex, geometry and fragment shader. Through a material we know which shader configuration to use while rendering a specific mesh, this works nicely until we need to consider that non-static meshes require a separate vertex shader, this can be implemented but adds a lot to the complexity of the system."}),(0,n.jsx)(a,{children:"Another problem is the fact that every time we need to render these skinned meshes for different passes or effects, we need a separate vertex shader than for static meshes, since the skinned vertex shader version does more work, they cost more to render, and this must be done every time we need to render the mesh during a frame."}),(0,n.jsx)(a,{children:"The solution that I went with performs the skinning of the vertices in a compute shader prior to rendering anything and writes the result into a separate vertex buffer that will later be used to render these meshes. This eliminates a lot of this complexity, skinned meshes can use the exact same vertex shader as static meshes, we no longer require extra shader combinations, no extra buffers must be bound while rendering skinned meshes, skinned meshes can use the exact same rendering code as static meshes, this also means that they are cheaper to render multiple times per frame because we no longer need extra work in the vertex shader."}),(0,n.jsx)(a,{children:"To limit the amount of data that our skinning compute shader needs to write and read per skinned mesh I split the vertex data into multiple streams, a stream with all data that needs to be skinned, another stream with the bone weights and ids and lastly everything that does not need to be adjusted. The skinned data only consist of position, normal and tangent."}),(0,n.jsx)(a,{children:"With this I brought the complexity of the rendering pipeline down even further and could remove a lot of duplicate code and extra cases, tons of vertex shaders and shader combinations could be removed since they are no longer needed, and it is now easier to create custom shader configurations without having to think about skinned meshes."})]}),(0,n.jsxs)(r.Z,{id:"shadow-map-atlas",title:"Shadow-map Atlas",children:[(0,n.jsx)(a,{children:"During the final shading pass we need to have the shadow-map texture for each light that casts shadows available. When a shadow casting light was created we had to allocate a new texture for the shadow-map, this texture had to be allocated with a particular size without much context to how important it was, how far away the player is, neither could it easily react to dynamic changes as the player moving closer or further away. When rendering the shadows we had to re-bind a new shadow-map texture for every light prior to rendering depth, as well as during the final shading pass we need access to all shadow-map textures since we are now rendering all lights at the same time for a given mesh with the clustered shading approach. To get this working we would need to figure out for a given mesh instance which shadow casting lights affect it and bind all those shadow-map textures to the pipeline prior to issuing the draw calls, as well as a method for the shader to figure out which texture corresponds to which light."}),(0,n.jsx)(a,{children:"This was not feasible and would lower the benefits achieved from clustered shading as well as increase complexity once again. To fix this I decided to implement shadows through an atlas approach. Instead of shadow casting lights needing a shadow-map texture without any context I would now allocate a large texture when the engine starts up, for now I went with 8192x8192. I created a ShadowMapManager that would be responsible for the texture as well as which lights own a particular area of the map. I set up different tiers of resolution Tier0 - Tier6, Tier0 being the largest at 4096x4096 and subsequent tiers halving the resolution. Now when a light is marked as a shadow caster we can reserve an area from the manager at a select tier, we can calculate the tier from context, how important is the light, how intense is it, how close is it to the player, any kind of metric we can think of. If we already have an area and want to change, we can just release it and reserve a new area at a different tier, if the manager can find an open slot in the texture with the correct size, it is reserved, otherwise we can easily skip rendering shadows for that light until a slot becomes available."}),(0,n.jsx)(a,{children:"With this approach we can dynamically and easily change the resolution of the shadow-map of a light without any new allocations or anything. When rendering depth to the shadow-maps we can just bind the shadow-map texture upfront, we no longer need to re-bind any textures. When doing the final shading pass, once again we bind the whole shadow-map texture, the shader now has the entire shadow-map available through a single texture with no re-bind needed. Now we only need to figure out which area a particular light uses in the shadow-map, this was solved by adding min and max UV coordinates to per-light data, with this information we can now easily sample from the correct part of the texture, this method was easily implemented for both directional- and spotlights."}),(0,n.jsx)(a,{children:"With this the rendering flow once again became less complex and more streamlined."}),(0,n.jsx)(a,{children:(0,n.jsx)("span",{children:"TODO: Add images, more text"})})]}),(0,n.jsxs)(r.Z,{id:"conclusion",title:"Conclusion",children:[(0,n.jsx)(a,{children:"I am pleased with the outcome of this project, I brought down the complexity of the rendering pipeline in our engine, eliminated tons of duplicate code and complex cases, brought down the number of shaders and got to experiment with compute shaders as well as implement clustered shading."}),(0,n.jsx)(a,{children:"I did not have time to do as much as I would have wanted, if I continued this project, I would like to find a neat way of implementing point lights into the shadow-map atlas, also a big performance improvement with shadows that I did not have time for is to only re-render slots of the shadow-map where something has changed, otherwise leave it the same as the previous frame."})]})]})},sections:[{id:"summary",title:"Summary"},{id:"clustered-shading",title:"Clustered Shading"},{id:"compute-skinning",title:"Skinning with Compute shaders"},{id:"shadow-map-atlas",title:"Shadow-map Atlas"},{id:"conclusion",title:"Conclusion"}],platforms:["windows"],engine:{engineName:"Wondrous Machine"},media:[{type:"image",source:"/images/projects/the-eternal/img-0.png"},{type:"image",source:"/images/projects/the-eternal/img-1.png"},{type:"image",source:"/images/projects/the-eternal/img-2.png"},{type:"image",source:"/images/projects/the-eternal/img-3.png"},{type:"image",source:"/images/projects/the-eternal/img-4.png"},{type:"image",source:"/images/projects/the-eternal/img-5.png"}],videoShowcase:{type:"video",source:"/videos/the-eternal.mp4"}},m={id:"aquatica-ultra",title:"Aquatica Ultra",summaryComponent:function(){return(0,n.jsx)(n.Fragment,{children:(0,n.jsx)(a,{children:"Aquatica Ultra was the third group project game at TGA with the theme shoot 'em up. The goal of the game is to push through waves of enemies to get deeper, along the way one will encounter multiple bosses & and stage themes."})})},platforms:["windows"],engine:{engineName:"Tga2D"},media:[{type:"image",source:"/images/projects/aquatica-ultra/img-0.png"},{type:"image",source:"/images/projects/aquatica-ultra/img-1.png"},{type:"image",source:"/images/projects/aquatica-ultra/img-2.png"},{type:"image",source:"/images/projects/aquatica-ultra/img-3.png"},{type:"image",source:"/images/projects/aquatica-ultra/img-4.png"},{type:"image",source:"/images/projects/aquatica-ultra/img-5.png"}],videoShowcase:{type:"yt",source:"https://www.youtube-nocookie.com/embed/zfDn8CPQ6xA"}},g=i(1417),u={id:"mistworld",title:"Mistworld",summaryComponent:function(){return(0,n.jsx)(n.Fragment,{children:(0,n.jsx)(a,{children:"This was our second group game project at TGA, this time we were tasked with a mobile puzzle game. The game consist of 12 stages, the goal of each is to get to the goal with the fewest amount of steps possible, each stage had a predetermined max number of moves, going past this would restart the stage."})})},platforms:["android","ios"],engine:{icon:g.Vrw,engineName:"Unity"},media:[{type:"image",source:"/images/projects/mistworld/img-0.png"},{type:"image",source:"/images/projects/mistworld/img-1.png"},{type:"image",source:"/images/projects/mistworld/img-2.png"},{type:"image",source:"/images/projects/mistworld/img-3.png"},{type:"image",source:"/images/projects/mistworld/img-4.png"}],videoShowcase:{type:"yt",source:"https://www.youtube-nocookie.com/embed/m1hP8STqr24"}},p={id:"flying-ace-ssay",title:"Flying Ace-ssay",summaryComponent:function(){return(0,n.jsx)(n.Fragment,{children:(0,n.jsx)(a,{children:"This was our first group game project at TGA with an open world theme. This game taught us how to work in a multidisciplinary group."})})},platforms:["windows"],engine:{icon:g.Vrw,engineName:"Unity"},media:[{type:"image",source:"/images/projects/flying-ace-ssay/img-0.png"},{type:"image",source:"/images/projects/flying-ace-ssay/img-1.png"},{type:"image",source:"/images/projects/flying-ace-ssay/img-2.png"},{type:"image",source:"/images/projects/flying-ace-ssay/img-3.png"},{type:"image",source:"/images/projects/flying-ace-ssay/img-4.png"}],videoShowcase:{type:"yt",source:"https://www.youtube-nocookie.com/embed/SNFOhPt55YE"}},w=function(e){var t=e.show,i=e.children;return(0,n.jsx)(n.Fragment,{children:t?i:void 0})};function f(e,t){(null==t||t>e.length)&&(t=e.length);for(var i=0,n=new Array(t);i<t;i++)n[i]=e[i];return n}function x(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function y(e){return function(e){if(Array.isArray(e))return f(e)}(e)||function(e){if("undefined"!==typeof Symbol&&null!=e[Symbol.iterator]||null!=e["@@iterator"])return Array.from(e)}(e)||function(e,t){if(!e)return;if("string"===typeof e)return f(e,t);var i=Object.prototype.toString.call(e).slice(8,-1);"Object"===i&&e.constructor&&(i=e.constructor.name);if("Map"===i||"Set"===i)return Array.from(i);if("Arguments"===i||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(i))return f(e,t)}(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}var b=[c,d],j=[m,u,p,{id:"the-eternal",title:"The Eternal",summaryComponent:function(e){var t=e.isSingle;return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(a,{children:["An endless runner mobile game. The goal is to climb as far as possible and get the best score with online leaderboards and statistics, all while avoiding the deadly traps lurking about.",(0,n.jsx)(w,{show:t,children:" The environment is generated as one climbs. As reward for getting a good score there are a multitude of different characters to unlock and play with."})]}),(0,n.jsx)(w,{show:t,children:(0,n.jsx)(a,{children:"We were two programmers and one graphical artist, with me as the main programmer. The development of this game taught me to work with the limitations and restrictions of mobile hardware, especially for lower end devices we targeted. To accomplish this I wrote a multitude of shaders to align with our art direction and keep us within our performance budget."})})]})},platforms:["android","ios"],engine:{icon:g.Vrw,engineName:"Unity"},media:[{type:"image",source:"/images/projects/the-eternal/img-0.png"},{type:"image",source:"/images/projects/the-eternal/img-1.png"},{type:"image",source:"/images/projects/the-eternal/img-2.png"},{type:"image",source:"/images/projects/the-eternal/img-3.png"},{type:"image",source:"/images/projects/the-eternal/img-4.png"},{type:"image",source:"/images/projects/the-eternal/img-5.png"}],videoShowcase:{type:"video",source:"/videos/the-eternal.mp4"}},{id:"cube-swing",title:"Cube Swing",summaryComponent:function(e){var t=e.isSingle;return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(a,{children:['An endless runner mobile game. A game based around shooting "ropes" to keep going forward, all while avoiding walls and other obstacles.',(0,n.jsx)(w,{show:t,children:" The game contains different game modes, like hardcore and time trials. As reward for getting further there are a multitude of characters to unlock and play with."})]}),(0,n.jsx)(w,{show:t,children:(0,n.jsx)(a,{children:"We were two programmers and one graphical artist, with me as the main programmer. This games also gave me a good opportunity to tinker around with physics."})})]})},platforms:["android","ios"],engine:{icon:g.Vrw,engineName:"Unity"},media:[{type:"image",source:"/images/projects/cube-swing/img-0.png"},{type:"image",source:"/images/projects/cube-swing/img-1.png"},{type:"image",source:"/images/projects/cube-swing/img-2.png"},{type:"image",source:"/images/projects/cube-swing/img-3.png"},{type:"image",source:"/images/projects/cube-swing/img-4.png"},{type:"image",source:"/images/projects/cube-swing/img-5.png"},{type:"image",source:"/images/projects/cube-swing/img-6.png"},{type:"image",source:"/images/projects/cube-swing/img-7.png"},{type:"image",source:"/images/projects/cube-swing/img-8.png"},{type:"image",source:"/images/projects/cube-swing/img-9.png"},{type:"image",source:"/images/projects/cube-swing/img-10.png"},{type:"image",source:"/images/projects/cube-swing/img-11.png"}],videoShowcase:{type:"video",source:"/videos/cube-swing.mp4"}}],v=y(b).concat(y(j)).reduce((function(e,t){return function(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{},n=Object.keys(i);"function"===typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(i).filter((function(e){return Object.getOwnPropertyDescriptor(i,e).enumerable})))),n.forEach((function(t){x(e,t,i[t])}))}return e}({},e,x({},t.id,t))}),{}),k=b,I=j}}]);